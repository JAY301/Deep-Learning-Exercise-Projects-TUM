{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"i2dl","language":"python","name":"i2dl"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.5"},"colab":{"name":"0_spatial_batchnorm-optional.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"JlwwnuUa0-Kr","colab_type":"text"},"source":["# (Optional) Spatial Batch Normalization\n","\n","<div class=\"alert alert-info\">\n","    <strong>Note:</strong> This exercise is optional and can be done for a better understanding of batch normalization. Using batch normalization with PyTorch does not require a distinction between normal and spatial.\n","</div>\n","\n","We already saw that batch normalization is a very useful technique for training deep fully-connected networks. Batch normalization can also be used for convolutional networks, but we need to tweak it a bit; the modification will be called \"spatial batch normalization.\"\n","\n","Normally batch-normalization accepts inputs of shape `(N, D)` and produces outputs of shape `(N, D)`, where we normalize across the minibatch dimension `N`. For data coming from convolutional layers, batch normalization needs to accept inputs of shape `(N, C, H, W)` and produce outputs of shape `(N, C, H, W)` where the `N` dimension gives the minibatch size and the `(H, W)` dimensions give the spatial size of the feature map.\n","\n","If the feature map was produced using convolutions, then we expect the statistics of each feature channel to be relatively consistent both between different image sand different locations within the same image. Therefore spatial batch normalization computes a mean and variance for each of the `C` feature channels by computing statistics over both the minibatch dimension `N` and the spatial dimensions `H` and `W`."]},{"cell_type":"code","metadata":{"id":"84qOFEX01BD8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"outputId":"01e12ef9-4343-4701-f3a4-d39f0858eb1e","executionInfo":{"status":"ok","timestamp":1579538506397,"user_tz":-60,"elapsed":22831,"user":{"displayName":"Jay Parmar","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBnXq-DXInmUQi33YCW1yBn2YcBuQ75rlXok8uegA=s64","userId":"04956736468405767144"}}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","root_path = 'gdrive/My Drive/i2dl/exercise_3'"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5P5vxZoh1BB5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"ae0a4b36-8705-4594-99d8-e3896f92c81b","executionInfo":{"status":"ok","timestamp":1579538511007,"user_tz":-60,"elapsed":800,"user":{"displayName":"Jay Parmar","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBnXq-DXInmUQi33YCW1yBn2YcBuQ75rlXok8uegA=s64","userId":"04956736468405767144"}}},"source":["%cd 'gdrive/My Drive/i2dl/exercise_3'"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/i2dl/exercise_3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hgKdvxLz0-Kt","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from exercise_code.data_utils import get_CIFAR10_data\n","from exercise_code.gradient_check import (eval_numerical_gradient_array,\n","                                  eval_numerical_gradient,\n","                                  rel_error)\n","from exercise_code.layers import (spatial_batchnorm_forward,\n","                          spatial_batchnorm_backward)\n","\n","%matplotlib inline\n","plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n","plt.rcParams['image.interpolation'] = 'nearest'\n","plt.rcParams['image.cmap'] = 'gray'\n","\n","# for auto-reloading external modules\n","# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n","%load_ext autoreload\n","%autoreload 2"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8GtFLP850-Kw","colab_type":"text"},"source":["## Spatial batch normalization: forward\n","\n","In the file `exercise_code/layers.py`, implement the forward pass for spatial batch normalization in the function `spatial_batchnorm_forward`. Check your implementation by running the following:"]},{"cell_type":"code","metadata":{"id":"_0UVGk6d0-Kx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":221},"outputId":"e29d62e3-0ef4-4d42-87f0-c24f89560a3c","executionInfo":{"status":"ok","timestamp":1579538742563,"user_tz":-60,"elapsed":871,"user":{"displayName":"Jay Parmar","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBnXq-DXInmUQi33YCW1yBn2YcBuQ75rlXok8uegA=s64","userId":"04956736468405767144"}}},"source":["# Check the training-time forward pass by checking means and variances\n","# of features both before and after spatial batch normalization\n","np.random.seed(0)\n","N, C, H, W = 2, 3, 4, 5\n","x = 4 * np.random.randn(N, C, H, W) + 10\n","\n","print('Before spatial batch normalization:')\n","print('  Shape: ', x.shape)\n","print('  Means: ', x.mean(axis=(0, 2, 3)))\n","print('  Stds: ', x.std(axis=(0, 2, 3)))\n","\n","# Means should be close to zero and stds close to one\n","gamma, beta = np.ones(C), np.zeros(C)\n","bn_param = {'mode': 'train'}\n","out, _ = spatial_batchnorm_forward(x, gamma, beta, bn_param)\n","print('After spatial batch normalization:')\n","print('  Shape: ', out.shape)\n","print('  Means: ', out.mean(axis=(0, 2, 3)))\n","print('  Stds: ', out.std(axis=(0, 2, 3)))\n","\n","# Means should be close to beta and stds close to gamma\n","gamma, beta = np.asarray([3, 4, 5]), np.asarray([6, 7, 8])\n","out, _ = spatial_batchnorm_forward(x, gamma, beta, bn_param)\n","print('After spatial batch normalization (nontrivial gamma, beta):')\n","print('  Shape: ', out.shape)\n","print('  Means: ', out.mean(axis=(0, 2, 3)))\n","print('  Stds: ', out.std(axis=(0, 2, 3)))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Before spatial batch normalization:\n","  Shape:  (2, 3, 4, 5)\n","  Means:  [10.43432714 10.95391914 10.20309468]\n","  Stds:  [3.6756692  4.33075715 4.45775619]\n","After spatial batch normalization:\n","  Shape:  (2, 3, 4, 5)\n","  Means:  [ 3.19189120e-17  1.13103971e-16 -5.55111512e-18]\n","  Stds:  [1.13789971 1.30851549 1.39556523]\n","After spatial batch normalization (nontrivial gamma, beta):\n","  Shape:  (2, 3, 4, 5)\n","  Means:  [6. 7. 8.]\n","  Stds:  [3.41369913 5.23406195 6.97782615]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NbBmlN2i0-K1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"c4732e8d-34a5-4c4b-8975-f7af17d2cf3e","executionInfo":{"status":"ok","timestamp":1579538746423,"user_tz":-60,"elapsed":1050,"user":{"displayName":"Jay Parmar","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBnXq-DXInmUQi33YCW1yBn2YcBuQ75rlXok8uegA=s64","userId":"04956736468405767144"}}},"source":["# Check the test-time forward pass by running the training-time\n","# forward pass many times to warm up the running averages, and then\n","# checking the means and variances of activations after a test-time\n","# forward pass.\n","\n","N, C, H, W = 10, 4, 11, 12\n","\n","bn_param = {'mode': 'train'}\n","gamma = np.ones(C)\n","beta = np.zeros(C)\n","for t in range(50):\n","    x = 2.3 * np.random.randn(N, C, H, W) + 13\n","    spatial_batchnorm_forward(x, gamma, beta, bn_param)\n","bn_param['mode'] = 'test'\n","x = 2.3 * np.random.randn(N, C, H, W) + 13\n","a_norm, _ = spatial_batchnorm_forward(x, gamma, beta, bn_param)\n","\n","# Means should be close to zero and stds close to one, but will be\n","# noisier than training-time forward passes.\n","print('After spatial batch normalization (test-time):')\n","print('  means: ', a_norm.mean(axis=(0, 2, 3)))\n","print('  stds: ', a_norm.std(axis=(0, 2, 3)))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["After spatial batch normalization (test-time):\n","  means:  [0.00892704 0.10813948 0.03228384 0.015115  ]\n","  stds:  [1.00292894 0.96849614 0.97537953 1.01534255]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"L2VJwdng0-K4","colab_type":"text"},"source":["## Spatial batch normalization: backward\n","In the file `exercise_code/layers.py`, implement the backward pass for spatial batch normalization in the function `spatial_batchnorm_backward`. Run the following to check your implementation using a numeric gradient check:"]},{"cell_type":"code","metadata":{"id":"H7ZPZHQn0-K6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"a1dc3daf-7960-4d22-f3cf-85afc73a27d5","executionInfo":{"status":"ok","timestamp":1579538751457,"user_tz":-60,"elapsed":729,"user":{"displayName":"Jay Parmar","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBnXq-DXInmUQi33YCW1yBn2YcBuQ75rlXok8uegA=s64","userId":"04956736468405767144"}}},"source":["N, C, H, W = 2, 3, 4, 5\n","x = 5 * np.random.randn(N, C, H, W) + 12\n","gamma = np.random.randn(C)\n","beta = np.random.randn(C)\n","dout = np.random.randn(N, C, H, W)\n","\n","bn_param = {'mode': 'train'}\n","fx = lambda x: spatial_batchnorm_forward(x, gamma, beta, bn_param)[0]\n","fg = lambda a: spatial_batchnorm_forward(x, gamma, beta, bn_param)[0]\n","fb = lambda b: spatial_batchnorm_forward(x, gamma, beta, bn_param)[0]\n","\n","dx_num = eval_numerical_gradient_array(fx, x, dout)\n","da_num = eval_numerical_gradient_array(fg, gamma, dout)\n","db_num = eval_numerical_gradient_array(fb, beta, dout)\n","\n","_, cache = spatial_batchnorm_forward(x, gamma, beta, bn_param)\n","dx, dgamma, dbeta = spatial_batchnorm_backward(dout, cache)\n","print('dx error: ', rel_error(dx_num, dx))\n","print('dgamma error: ', rel_error(da_num, dgamma))\n","print('dbeta error: ', rel_error(db_num, dbeta))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["dx error:  1.0\n","dgamma error:  9.559587960496967e-12\n","dbeta error:  7.41145863272442e-12\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tBO7YoW70-K-","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}